## 从正例和无标注数据中学习



# 一. 阅读< Building Text Classifiers Using Positive and Unlabeled Examples >有感 

问题： 机器学习没有负样本。只用正样本和无标签样本来学习分类器

解决： 



# 二. PU learning

## 1. 问题

给定一个正例文档集合P和一个无标注文档集U（混合文档集？可能就是光有单词，没有顺序？），在无标注文档集中同时含有正例文档和反例文档。

通过使用P和U建立一个分类器能够辨别U或测试集中的正例文档 【即想要精确分类U或测试集中的正例文档和反例文档】

## 2. 理论 

问题最终被转换成一个有**限制的最优化问题**（Constrained Optimization Problem），即算法试图在使得正例数据中的错误率低于1-r的情况下最小化无标注数据中正例数据的数目。

基于限制最优化问题，可采用两种方法来建立PU分类器：

两步方法（Two-step Approach）

直接方法（Direct Approach）

## 3. 两步方法 

![](http://orkjdoapd.bkt.clouddn.com/Machine-Learning-Study-Note/PU%20learning.png)

### 1）

通过正例数据从无标注数据集U中找到一些可靠的反例文档集合（Reliable Negative Documents/RN）

**采用的技术：**

* **间谍技术（Spy Technique）：**该技术从正例标注集P中选取一些“间谍”文档发送到无标注数据集U中去，

  ​a. 随机地从P中选取一个正例文档集合S，并把S加入到U中

  b. 通过把P-S当成是正例集合，Us当成是反例集合，在这两个集合上运行朴素贝叶斯算法，得到NB分类器被   用于给Us中的每个文档d进行分类，即为每个文档赋予一个概率类别标识Pr(1|d)，其中1代表正例类别

  ​c. 利用间谍文档的概率标识来决定哪些文档最有可能是反例。使用一个阈值t来确定，U中那些概率Pr(1|d)小于t的文档被认为是最有可能的反例文档，用RN表示。

* **1DNF技术：**首先建立一个正例特征集合PF，其中包括那些在正例集合P中出现次数大于在无标注数据U中出现次数的单词，得到U与P中出现的所有单词并得到一个词汇表V，从U中发现可靠反例文档，U中的某个文档如果不含有PF中任何特征的话被认为是一个可靠的反例文档。
* **NB（朴素贝叶斯）技术：**用NB分类器从无标注数据集U中发现一组可靠反例集合RN。
* **Rocchio技术：**与NB技术类似，只需有Rocchio分类器代替NB分类器。

### 2）

利用正例文档集合P、从无标注数据集中找到的可靠反例文档RN和U-RN（Q=U-RN，Q也被称为无标注数据集中可能正比例集）来建立分类器。

根据RN集合中数据的质量和数量的不同，在该步骤中可能会使用某个现有的学习算法一次或循环使用多次。

算法循环向RN中不断加入文档来改进分类器效果知道收敛。

算法在保证p的正例文档被正确分类的前提下，不断加入无标注数据集中被标为反例的文档数量

**采用的技术：**

在P和RN上运行一个学习算法（如NB或SVM），集合U-RN中的文档不在考虑范围内；迭代地运行某个学习算法直到它收敛或达到某个停止条件。

**使用NB分类器的EM算法**

**迭代SVM（Iterative SVM）：**该方法中，SVM通过使用P，RN和Q（U-RN）不断地循环运行。

**选择分类器**





# 三. 阅读 Positive-unlabeled learning in streaming networks 

## 1. 问题

社会网络数据特点：

* 天生的positive-unlabeled data. 

* 具有时序

  ​